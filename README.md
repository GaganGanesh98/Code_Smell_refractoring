AI-Driven Code Refactoring & Technical Debt Reduction

An end-to-end machine learning pipeline for predicting code refactoring impact and optimizing technical debt reduction using XGBoost and statistical validation.

This project explores how AI can assist software developers in prioritizing refactoring decisions by predicting complexity reduction and comparing AI-driven selection strategies against traditional static-rule baselines.

‚∏ª
 Project Overview

Modern software systems accumulate technical debt over time, leading to:
	‚Ä¢	Reduced maintainability
	‚Ä¢	Increased bug-proneness
	‚Ä¢	Higher long-term development cost

This project builds a data-driven AI system that:
	1.	Predicts refactoring benefit (delta_complexity)
	2.	Prioritizes files under a fixed refactoring budget
	3.	Compares AI vs rule-based vs random baselines
	4.	Validates results using bootstrap statistical testing
	5.	Interprets model decisions using SHAP

‚∏ª

Research Goal

Can AI optimize refactoring prioritization better than traditional static rules?

We evaluate whether a machine learning model can identify files that yield higher complexity reduction compared to:
	‚Ä¢	Random selection
	‚Ä¢	Static threshold rules (LOC / Cyclomatic Complexity)
	‚Ä¢	Technical debt‚Äìbased ranking

‚∏ª

üóÇ Dataset

Synthetic but structurally realistic dataset of:
	‚Ä¢	120,000 files
	‚Ä¢	15 code smell types
	‚Ä¢	Multiple programming languages
	‚Ä¢	Pre- and post-refactoring complexity metrics

Key Features

Feature	Description
lines_of_code	File size
cyclomatic_complexity	Structural complexity
num_methods	Method count
num_classes	Class count
technical_debt_minutes	Estimated technical debt
maintainability_index	Maintainability score
bug_prone_score	Bug likelihood
developer_experience_years	Developer expertise
pre_refactor_complexity	Before refactoring
post_refactor_complexity	After refactoring

Target variable:

delta_complexity = pre_refactor_complexity - post_refactor_complexity


‚∏ª

Model Architecture

 Regression Model
	‚Ä¢	Model: XGBoost Regressor
	‚Ä¢	Objective: Predict delta_complexity
	‚Ä¢	Hyperparameter search + early stopping
	‚Ä¢	SHAP-based interpretability

 Classification Model
	‚Ä¢	Model: XGBoost Classifier
	‚Ä¢	15 smell classes
	‚Ä¢	Evaluated using macro-F1 and confusion matrix

‚∏ª

Results

Regression Performance

Metric	Value
MAE	9.71
RMSE	11.23
R¬≤	0.667

The model explains ~67% of variance in complexity reduction.

Feature importance shows:

pre_refactor_complexity ‚Üí strongest predictor


‚∏ª

Refactoring Budget Experiment

We simulate a fixed refactoring budget (Top 10% of files).

Comparison

Strategy	Avg Delta	% Positive Improvements
Random	~11.9	70%
Static Rule	~12.0	70%
Debt Ranking	~11.3	69%
AI (XGBoost)	37.17	100%
Oracle	45.23	100%


‚∏ª

Bootstrap Validation

1000 bootstrap iterations:
	‚Ä¢	AI vs Debt baseline:
	‚Ä¢	Mean improvement: +25.9
	‚Ä¢	95% CI: [25.01, 26.84]
	‚Ä¢	AI wins in 100% of samples
	‚Ä¢	AI vs Static Rule:
	‚Ä¢	Mean improvement: +25.17
	‚Ä¢	AI wins in 100% of samples

Statistically significant superiority.

‚∏ª

Interpretability (SHAP)

SHAP analysis confirms:
	‚Ä¢	pre_refactor_complexity is dominant driver
	‚Ä¢	Structural metrics provide secondary signals

This improves trust and explainability of the prioritization system.

‚∏ª

Important Findings

1. Regression works well

AI can effectively prioritize refactoring candidates.

2. Smell classification is difficult

Predicting specific code smell types from coarse metrics yields near-random performance (~6.6% macro-F1 for 15 classes).

This highlights that:

Code smell detection requires richer structural/AST-level features.

‚∏ª

Repository Structure

‚îú‚îÄ‚îÄ AI_Code_Refactoring.ipynb
‚îú‚îÄ‚îÄ xgb_reg_booster.json
‚îú‚îÄ‚îÄ xgb_preprocess.joblib
‚îú‚îÄ‚îÄ figures/
‚îú‚îÄ‚îÄ dataset/
‚îú‚îÄ‚îÄ README.md


‚∏ª

 How to Run

1. Install dependencies

pip install -r requirements.txt

Or manually:

pip install pandas numpy scikit-learn xgboost shap matplotlib seaborn joblib

2. Open notebook

jupyter notebook AI_Code_Refactoring.ipynb

3. Run all cells

‚∏ª

 Experimental Components
	‚Ä¢	Feature engineering
	‚Ä¢	Hyperparameter search
	‚Ä¢	Early stopping
	‚Ä¢	Confusion matrix visualization
	‚Ä¢	Bootstrap statistical testing
	‚Ä¢	Budget sensitivity analysis
	‚Ä¢	SHAP explainability

‚∏ª

 Academic Context

This project aligns with:

‚ÄúHow Can AI Assist Software Developers in Automated Code Refactoring and Technical Debt Reduction?‚Äù

Relevant for:
	‚Ä¢	Software Engineering
	‚Ä¢	AI for DevOps
	‚Ä¢	Technical Debt Research
	‚Ä¢	Intelligent Code Analysis

‚∏ª

 Technologies Used
	‚Ä¢	Python
	‚Ä¢	XGBoost
	‚Ä¢	Scikit-learn
	‚Ä¢	SHAP
	‚Ä¢	Pandas / NumPy
	‚Ä¢	Matplotlib / Seaborn

‚∏ª

 Future Improvements
	‚Ä¢	AST-level structural features
	‚Ä¢	Graph-based code representations
	‚Ä¢	Real-world repository dataset
	‚Ä¢	Hierarchical smell classification
	‚Ä¢	Integration into CI/CD pipelines

‚∏ª
